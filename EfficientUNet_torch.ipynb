{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q segmentation-models-pytorch albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch & related libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Other utilities\n",
    "import albumentations as albu\n",
    "from skimage.exposure import adjust_gamma\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(probability, threshold, min_size):\n",
    "    \"\"\"\n",
    "    Post processing of each predicted mask, components with lesser number of pixels\n",
    "    than `min_size` are ignored\n",
    "    \"\"\"\n",
    "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros((350, 525), np.float32)\n",
    "    num = 0\n",
    "    for c in range(1, num_component):\n",
    "        p = (component == c)\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "            num += 1\n",
    "    return predictions, num\n",
    "\n",
    "def np_resize(img, input_shape):\n",
    "    \"\"\"\n",
    "    Reshape a numpy array, which is input_shape=(height, width),\n",
    "    as opposed to input_shape=(width, height) for cv2\n",
    "    \"\"\"\n",
    "    height, width = input_shape\n",
    "    return cv2.resize(img, (width, height))\n",
    "\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle2mask(rle, input_shape):\n",
    "    width, height = input_shape[:2]\n",
    "    mask= np.zeros( width*height ).astype(np.uint8)\n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "    current_position = 0\n",
    "    for index, start in enumerate(starts):\n",
    "        mask[int(start):int(start+lengths[index])] = 1\n",
    "        current_position += lengths[index]\n",
    "    return mask.reshape(height, width).T\n",
    "\n",
    "def build_masks(rles, input_shape, reshape=None):\n",
    "    depth = len(rles)\n",
    "    if reshape is None:\n",
    "        masks = np.zeros((*input_shape, depth))\n",
    "    else:\n",
    "        masks = np.zeros((*reshape, depth))\n",
    "\n",
    "    for i, rle in enumerate(rles):\n",
    "        if type(rle) is str:\n",
    "            if reshape is None:\n",
    "                masks[:, :, i] = rle2mask(rle, input_shape)\n",
    "            else:\n",
    "                mask = rle2mask(rle, input_shape)\n",
    "                reshaped_mask = np_resize(mask, reshape)\n",
    "                masks[:, :, i] = reshaped_mask\n",
    "\n",
    "    return masks\n",
    "\n",
    "def build_rles(masks, reshape=None):\n",
    "    width, height, depth = masks.shape\n",
    "    rles = []\n",
    "    for i in range(depth):\n",
    "        mask = masks[:, :, i]\n",
    "        if reshape:\n",
    "            mask = mask.astype(np.float32)\n",
    "            mask = np_resize(mask, reshape).astype(np.int64)\n",
    "        rle = mask2rle(mask)\n",
    "        rles.append(rle)\n",
    "    return rles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/understanding_cloud_organization/train.csv')\n",
    "train_df['ImageId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "train_df['ClassId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "train_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\n",
    "\n",
    "mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\n",
    "mask_count_df.sort_values('hasMask', ascending=False, inplace=True)\n",
    "\n",
    "sub_df = pd.read_csv('../input/understanding_cloud_organization/sample_submission.csv')\n",
    "sub_df['ImageId'] = sub_df['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "test_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, df, list_IDs, mode='fit',\n",
    "                 base_path='../input/understanding_cloud_organization/train_images',\n",
    "                 dim=(1400, 2100), reshape=(320, 480), gamma=0.8,\n",
    "                 augment_fn=None, n_classes=4):\n",
    "        self.dim = dim\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        self.base_path = base_path\n",
    "        self.list_IDs = list_IDs\n",
    "        self.reshape = reshape\n",
    "        self.gamma = gamma\n",
    "        self.augment_fn = augment_fn\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get image and mask paths\n",
    "        img_id = self.list_IDs[index]\n",
    "        im_name = self.df['ImageId'].iloc[img_id]\n",
    "        img_path = f\"{self.base_path}/{im_name}\"\n",
    "\n",
    "        # Load and preprocess image\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.reshape:\n",
    "            img = cv2.resize(img, (self.reshape[1], self.reshape[0]))\n",
    "        if self.gamma:\n",
    "            img = adjust_gamma(img, gamma=self.gamma)\n",
    "        \n",
    "        # Normalize and transpose for PyTorch (C, H, W)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = img.transpose(2, 0, 1)\n",
    "        img_tensor = torch.from_numpy(img)\n",
    "\n",
    "        # Handle prediction case (no labels)\n",
    "        if self.mode == 'predict':\n",
    "            return img_tensor\n",
    "\n",
    "        # Get masks\n",
    "        image_df = self.df[self.df['ImageId'] == im_name]\n",
    "        rles = image_df['EncodedPixels'].values\n",
    "        masks = build_masks(rles, input_shape=self.dim, reshape=self.reshape)\n",
    "        masks = masks.transpose(2, 0, 1) # (H, W, C) -> (C, H, W)\n",
    "        masks_tensor = torch.from_numpy(masks.astype(np.float32))\n",
    "\n",
    "        return img_tensor, masks_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create segmentation model with specified encoder and weights\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"efficientnet-b4\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=4,\n",
    ")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original notebook used: model.load_weights(\"../input/cloudmodels/EfficientNetB4.h5\")\n",
    "# This is the PyTorch equivalent. You must replace the path with a valid .pth file.\n",
    "try:\n",
    "    # --- YOU MUST PROVIDE A PYTORCH-COMPATIBLE .pth WEIGHT FILE HERE ---\n",
    "    weights_path = \"../input/your-pytorch-weights/efficientnet-b4-unet.pth\"\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "    print(f\"Loaded weights from {weights_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: PyTorch weights file not found. Using pre-trained ImageNet weights for the encoder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction parameters (unchanged)\n",
    "minsizes = [20000, 20000, 22500, 10000]\n",
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Create test dataset and dataloader\n",
    "test_dataset = CloudDataset(\n",
    "    df=test_imgs,\n",
    "    list_IDs=list(range(test_imgs.shape[0])),\n",
    "    mode='predict',\n",
    "    base_path='../input/understanding_cloud_organization/test_images',\n",
    "    reshape=(320, 480),\n",
    "    gamma=0.8\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=4, # You can increase batch_size for faster inference on GPU\n",
    "    shuffle=False,\n",
    "    num_workers=num_cores\n",
    ")\n",
    "\n",
    "# Prediction loop\n",
    "test_df_list = []\n",
    "model.eval() # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for i, batch_images in enumerate(tqdm(test_loader)):\n",
    "        batch_images = batch_images.to(device)\n",
    "        batch_preds = model(batch_images)\n",
    "        # Apply sigmoid and move to CPU\n",
    "        batch_preds = batch_preds.sigmoid().cpu().numpy()\n",
    "\n",
    "        for j in range(batch_preds.shape[0]):\n",
    "            # Get the original image filename\n",
    "            original_idx = i * test_loader.batch_size + j\n",
    "            filename = test_imgs['ImageId'].iloc[original_idx]\n",
    "            image_df = sub_df[sub_df['ImageId'] == filename].copy()\n",
    "\n",
    "            # Transpose back to (H, W, C) for cv2/numpy functions\n",
    "            pred_masks = batch_preds[j,].transpose(1, 2, 0)\n",
    "            pred_masks = cv2.resize(pred_masks, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            processed_masks = np.zeros((350, 525, 4), dtype=np.float32)\n",
    "            for t in range(4):\n",
    "                a, num_predict = post_process(pred_masks[:, :, t], 0.6, minsizes[t])\n",
    "                processed_masks[:, :, t] = a\n",
    "            \n",
    "            pred_rles = build_rles(processed_masks)\n",
    "            image_df['EncodedPixels'] = pred_rles\n",
    "            test_df_list.append(image_df)\n",
    "\n",
    "final_sub_df = pd.concat(test_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub_df = final_sub_df[['Image_Label', 'EncodedPixels']]\n",
    "final_sub_df.to_csv('submission.csv', index=False)\n",
    "display(final_sub_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AC4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
